{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# `\"pidgin\"` programming - literate programming for modern science\n",
       "\n",
       "pidgin programming is fun and expressive way to interact\n",
       "with literature and code in jupyter notebooks.\n",
       "polyglot multilingual."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:24.135680",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:24.130842"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `\"pidgin\"` programming - literate programming for modern science\n",
    "\n",
    "pidgin programming is fun and expressive way to interact\n",
    "with literature and code in jupyter notebooks.\n",
    "polyglot multilingual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    import jupyter, notebook, notebook as üìì, IPython, pidgy, pidgy as üê¶, mistune as markdown, mistune as M‚¨áÔ∏è, IPython as python, ast, jinja2 as template, importnb as _import_, doctest, pathlib, graphviz    \n",
    "    with üê¶.reuse.pidgyLoader(lazy=True):        \n",
    "        import pidgy.conversion, pidgy.cli, pidgy.tests.readme\n",
    "        try: \n",
    "            from . import appendix, intro, test_pidgin_syntax, paper\n",
    "        except:\n",
    "            import appendix, intro, test_pidgin_syntax, paper\n",
    "    shell = IPython.get_ipython()\n",
    "    import pandas as üêº\n",
    "    √ò = __name__ == '__main__'\n",
    "    from graphviz import Source as üï∏\n",
    "\n",
    "    formats = !pandoc --list-input-formats\n",
    "    formats = {x.split('_')[0] for x in formats}\n",
    "    kernels = üêº.read_html(appendix.get('https://github.com/jupyter/jupyter/wiki/Jupyter-kernels'))[0]\n",
    "\n",
    "\n",
    "    \n",
    "    import nbformat as schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Literate programming and computing\n",
       "\n",
       "pidgin is inspired by web and literate coffeescript.\n",
       "\n",
       "`\"pidgin\"` literate programming is a specification & implementation for writing computational essays \n",
       "that freely use natural and programming languages to bring meaning a subject and theme.\n",
       "Donald Knuth introduced literate programming in 1979 as an approach to writing \n",
       "documentation written with the shared intent of being both literature and a program.\n",
       "Since, rote software development styles have prevailed \n",
       "for most topics dependent on programming languages.\n",
       "Increasingly, we are seeing a rise in literate programs with the\n",
       "successful adoption of computational notebooks as substrates\n",
       "for data-driven narratives.\n",
       "Thoughout this document we'll implement `pidgy`, a literate programming\n",
       "interface in `jupyter` `notebook`s running using the `ipykernel`,\n",
       "and we'll discuss how modern software practices can be used\n",
       "to create readable, reproducible, & reusable computational literature.\n",
       "\n",
       "One of the most charming features of `\"literate programming\"` is the \n",
       "authentic pleasure of writing that Donald Knuth describes while \n",
       "discussing about novel technical content.\n",
       "The outcome is a paper that is a pleasure to read.\n",
       "The `pidgy` implementation had to be written to test\n",
       "how enjoyable literate programming can be.\n",
       "Hopefully think document does demonstrate and confirm how fun\n",
       "writing about technical scientific content may be.\n",
       "\n",
       "Only in the wake of the literate programming did we learn of\n",
       "(1) unit testing, (2) notebook interfaces, and (3) the world wide web.\n",
       "`\"pidgin\"` programming promotes literate programming \n",
       "as a means of writing data-driven narratives in computational notebooks.\n",
       "`notebook`s are a natural substrate for reproducible, literate programs\n",
       "because their schema refers explicitly to \n",
       "two primary cell types: `markdown and \"code\"`.\n",
       "It follows that `üê¶ `'s document language is `markdown`\n",
       "with `IPython, python` as the glue programming language.\n",
       "\n",
       "\n",
       "\n",
       "In `üê¶, pidgy and \"pidgin\"` programming, units (ie. cells)\n",
       "in a `notebook` are written in `markdown` with the \n",
       "shared intent of designing readable outputs\n",
       "and source that `python` can `compile`.\n",
       "`pidgy` demonstrates this behavior with\n",
       "extensions for the `IPython.InteractiveShell` and `ipykernel`\n",
       "that augments the interactive REPL experience to be \n",
       "suitable for an implicit literate programming experience.\n",
       "Authors interactively read, write, and revise their \n",
       "input as units readable output units,\n",
       "as working code units,\n",
       "and formal test objects.\n",
       "\n",
       "`\"pidgin\"` documents are flexible formats that can \n",
       "be transformed in varities of literature, source code, and formal tests.\n",
       "`pidgy` relies on open source infrastructure to \n",
       "provide multiple reusable states of `pidgy` documents. \n",
       "`pidgy` documents abide an `nbformat` version which \n",
       "identifies a `jsonschema` that validates the shape of the document.\n",
       "From the `nbformat`, \n",
       "`nbconvert` transforms `notebook`s to other file formats (eg. `markdown and python`),\n",
       "`importnb` allows `pidgy` documents to be import like any python module, \n",
       "`doctest` to provide interactive documentation testing,\n",
       "and `pytest` to establish formal testing procedures for `pidgy` documents.\n",
       "\n",
       "Open source communities have worked together to \n",
       "improve access scientific computing technologies.\n",
       "Increased access to scientific computing technologies\n",
       "has reduced the demand for verbose code bases\n",
       "and may be acheived by a simple api.\n",
       "As such, non programmers can begin to participate in\n",
       "interactive computing through their abilities to tell stories.\n",
       "\n",
       "`pidgy` is hella fun to write in.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:25.056691",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:24.964828"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Literate programming and computing\n",
    "\n",
    "pidgin is inspired by web and literate coffeescript.\n",
    "\n",
    "{{appendix.exports(intro)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## The `pidgy` ismplementation\n",
       "\n",
       "> **What follows is the implementation of `pidgy` as a literate program in `jupyter` `notebook`s.  `notebook`s are the source code for the implementation.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:25.245772",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:25.236052"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The `pidgy` ismplementation\n",
    "\n",
    "> **What follows is the implementation of `pidgy` as a literate program in `jupyter` `notebook`s.  `notebook`s are the source code for the implementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### The `notebook` `format` as a basis from literate programs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:26.009297",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:26.003851"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### The `notebook` `format` as a basis from literate programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"555pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 555.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 551,-184 551,4 -4,4\"/>\n",
       "<!-- notebook -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>notebook</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"276\" cy=\"-162\" rx=\"43.0387\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">notebook</text>\n",
       "</g>\n",
       "<!-- documentation -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>documentation</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"147\" cy=\"-90\" rx=\"62.8252\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">documentation</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;documentation -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;documentation</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M249.8949,-147.4297C231.1686,-136.9778 205.6535,-122.7369 184.7167,-111.0512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.1973,-107.8693 175.7595,-106.0518 182.7857,-113.9817 186.1973,-107.8693\"/>\n",
       "</g>\n",
       "<!-- html -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>html</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">html</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;html -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;html</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.3654,-155.985C181.5176,-147.2913 90.358,-129.8362 65,-108 46.6133,-92.1669 36.9096,-65.9231 31.9262,-45.849\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"35.3229,-44.9999 29.7296,-36.0018 28.4909,-46.524 35.3229,-44.9999\"/>\n",
       "</g>\n",
       "<!-- pdf -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>pdf</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"103\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"103\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pdf</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;pdf -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;pdf</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.5977,-156.8033C181.5988,-149.2026 94.2936,-133.1611 75,-108 60.3207,-88.8565 71.8335,-61.9152 84.24,-42.5055\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.1785,-44.4086 89.9123,-34.1726 81.3919,-40.4696 87.1785,-44.4086\"/>\n",
       "</g>\n",
       "<!-- tex -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>tex</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"177\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tex</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;tex -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;tex</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M265.5589,-144.4218C254.4813,-126.0402 236.2331,-96.5101 219,-72 211.9917,-62.0323 203.8552,-51.3811 196.6203,-42.1952\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.2516,-39.8807 190.2878,-34.2326 193.7729,-44.2379 199.2516,-39.8807\"/>\n",
       "</g>\n",
       "<!-- python -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>python</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"377\" cy=\"-90\" rx=\"34.8458\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"377\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">python</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;python -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;python</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M297.9155,-146.3771C312.6012,-135.9081 332.0956,-122.011 348.0547,-110.6343\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"350.393,-113.2657 356.5041,-104.6109 346.3296,-107.5657 350.393,-113.2657\"/>\n",
       "</g>\n",
       "<!-- CLI -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>CLI</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"250\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"250\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">CLI</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;CLI -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;CLI</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M272.7071,-143.7623C268.2529,-119.0928 260.2663,-74.8598 255.0507,-45.9731\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.4874,-45.3086 253.2662,-36.0896 251.5988,-46.5524 258.4874,-45.3086\"/>\n",
       "</g>\n",
       "<!-- extension -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>extension</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"339\" cy=\"-18\" rx=\"43.9992\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"339\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">extension</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;extension -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;extension</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M283.8516,-144.0535C294.7098,-119.2347 314.4027,-74.2224 327.0813,-45.2428\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"330.4457,-46.2848 331.2473,-35.7204 324.0325,-43.4791 330.4457,-46.2848\"/>\n",
       "</g>\n",
       "<!-- module -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>module</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"438\" cy=\"-18\" rx=\"36.7663\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"438\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">module</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;module -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;module</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.963,-157.5056C350.9141,-151.6941 395.3731,-138.395 421,-108 435.3562,-90.9727 439.0921,-65.6368 439.5314,-46.1808\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"443.0309,-46.05 439.4829,-36.0669 436.031,-46.0837 443.0309,-46.05\"/>\n",
       "</g>\n",
       "<!-- tests -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>tests</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"520\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"520\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tests</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;tests -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;tests</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M316.1599,-155.4379C351.7919,-148.1883 404.0801,-133.9416 443,-108 468.4875,-91.0116 490.384,-63.3222 504.2393,-43.1365\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"507.211,-44.9887 509.8476,-34.7271 501.3873,-41.1048 507.211,-44.9887\"/>\n",
       "</g>\n",
       "<!-- documentation&#45;&gt;html -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>documentation&#45;&gt;html</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M119.7701,-73.6621C100.7867,-62.272 75.4901,-47.094 56.1077,-35.4646\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.7682,-32.3793 47.3925,-30.2355 54.1667,-38.3817 57.7682,-32.3793\"/>\n",
       "</g>\n",
       "<!-- documentation&#45;&gt;pdf -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>documentation&#45;&gt;pdf</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136.1236,-72.2022C130.878,-63.6186 124.4875,-53.1613 118.7241,-43.7303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.6493,-41.805 113.4483,-35.0972 115.6764,-45.4551 121.6493,-41.805\"/>\n",
       "</g>\n",
       "<!-- documentation&#45;&gt;tex -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>documentation&#45;&gt;tex</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M154.5703,-71.8314C157.9865,-63.6323 162.0906,-53.7824 165.849,-44.7624\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.1272,-45.9947 169.7426,-35.4177 162.6656,-43.3023 169.1272,-45.9947\"/>\n",
       "</g>\n",
       "<!-- python&#45;&gt;CLI -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>python&#45;&gt;CLI</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M353.4099,-76.6261C332.6045,-64.8309 302.1864,-47.586 279.7229,-34.8508\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"281.3624,-31.757 270.937,-29.8698 277.9101,-37.8464 281.3624,-31.757\"/>\n",
       "</g>\n",
       "<!-- python&#45;&gt;extension -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>python&#45;&gt;extension</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M367.8013,-72.5708C363.3862,-64.2055 357.9989,-53.998 353.0831,-44.6839\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"356.141,-42.9791 348.378,-35.7689 349.9503,-46.2464 356.141,-42.9791\"/>\n",
       "</g>\n",
       "<!-- python&#45;&gt;module -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>python&#45;&gt;module</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M391.1479,-73.3008C398.8128,-64.2537 408.4339,-52.8977 416.9602,-42.8338\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"419.7114,-45.001 423.5052,-35.1086 414.3705,-40.476 419.7114,-45.001\"/>\n",
       "</g>\n",
       "<!-- python&#45;&gt;tests -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>python&#45;&gt;tests</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M401.9087,-77.4586C426.1399,-65.2582 463.0161,-46.6912 489.1042,-33.5559\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"490.8264,-36.6075 498.1841,-28.9842 487.6784,-30.3553 490.8264,-36.6075\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1167d74e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The `notebook` flexible format for numerous input and output languages.\n",
       "The `notebook` relies on a consistent data structure, that may be validated be a `schema`,\n",
       "that serializes literate programs.  The `notebook` has two primary cell types:\n",
       "\n",
       "1. Markdown Cells\n",
       "    \n",
       "    Cells that are typically rendered as rich html, but have a plain-text representation.\n",
       "    \n",
       "2. Code Cells\n",
       "\n",
       "    Cells that may be executed by a compiler external to a document.  \n",
       "    From the document perspective, code cells are forms that tangle to\n",
       "    rich assemblages of mimetypes.\n",
       "    \n",
       "In `pidgy` programming, we look at notebooks as polyglot collages of \n",
       "input and output mimetypes.\n",
       "\n",
       "\n",
       "    return üï∏(\"digraph {notebook->{documentation->{html pdf tex} python->{CLI extension module tests}}}\")\n",
       "    \n",
       "<details><summary>Short list of output formats</summary><ul>\n",
       "<li>org</li>\n",
       "<li>tikiwiki</li>\n",
       "<li>html</li>\n",
       "<li>markdown</li>\n",
       "<li>creole</li>\n",
       "<li>jats</li>\n",
       "<li>textile</li>\n",
       "<li>vimwiki</li>\n",
       "<li>rst</li>\n",
       "<li>docbook</li>\n",
       "<li>fb2</li>\n",
       "<li>gfm</li>\n",
       "<li>latex</li>\n",
       "<li>odt</li>\n",
       "<li>epub</li>\n",
       "<li>opml</li>\n",
       "<li>docx</li>\n",
       "<li>mediawiki</li>\n",
       "<li>commonmark</li>\n",
       "<li>muse</li>\n",
       "<li>json</li>\n",
       "<li>haddock</li>\n",
       "<li>t2t</li>\n",
       "<li>twiki</li>\n",
       "<li>native</li>\n",
       "</ul>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:26.275005",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:26.228790"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "The `notebook` flexible format for numerous input and output languages.\n",
    "The `notebook` relies on a consistent data structure, that may be validated be a `schema`,\n",
    "that serializes literate programs.  The `notebook` has two primary cell types:\n",
    "\n",
    "1. Markdown Cells\n",
    "    \n",
    "    Cells that are typically rendered as rich html, but have a plain-text representation.\n",
    "    \n",
    "2. Code Cells\n",
    "\n",
    "    Cells that may be executed by a compiler external to a document.  \n",
    "    From the document perspective, code cells are forms that tangle to\n",
    "    rich assemblages of mimetypes.\n",
    "    \n",
    "In `pidgy` programming, we look at notebooks as polyglot collages of \n",
    "input and output mimetypes.\n",
    "\n",
    "\n",
    "    return üï∏(\"digraph {notebook->{documentation->{html pdf tex} python->{CLI extension module tests}}}\")\n",
    "    \n",
    "<details><summary>Short list of output formats</summary><ul>\n",
    "{% for format in formats %}<li>{{format}}</li>\n",
    "{% endfor %}</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Derived applications of pidgin programs.\n",
       "\n",
       "\n",
       "\n",
       "    @click.group()\n",
       "    def application()->None:\n",
       "A successful `notebook` program could find uses outside of its\n",
       "interactive state as programs, documentation, or tests.\n",
       "`pidgy` programming includes a `click` command-line \n",
       "`application` to weave `notebook`s to other forms and tangle `notebook`s as source code.\n",
       "\n",
       "\n",
       "\n",
       "    def document(to, files):\n",
       "The `document` command is an opinionated wrapper that \n",
       "converts notebooks to formatted python programs\n",
       "and readable documents.\n",
       "\n",
       "        exporter = nbconvert.get_exporter(to)\n",
       "It uses the `nbconvert` library that transforms the `nbformat` into other projections.\n",
       "\n",
       "        if to in _CODE_FORMATS: \n",
       "`pidgy` introduces a new opinion to the notebook where\n",
       "the input defines the output.\n",
       "In literate programming terms, \n",
       "we tangle the input and weave the output.\n",
       "The decoupling of the input & output means that proper\n",
       "python code maybe extracted from the `input`.  `pidgy`\n",
       "includes `‚¨õÔ∏è and isort` community conventions \n",
       "for formatting python to abide python styling guides.\n",
       "\n",
       "            exporter = PythonExporter()\n",
       "        else:\n",
       "With `pidgy`, we may consider a cell output to be the intended\n",
       "`display` set forth by an author.\n",
       "A string opinion `pidgy` documents is that the `input`\n",
       "is excluded from resulting document, where as typical\n",
       "approaches view all code as essential or not essential.\n",
       "            \n",
       "            exporter = exporter(exclude_input=True)\n",
       "        \n",
       "        for file in files: ...\n",
       "    \n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    def run(files):\n",
       "The `document` function demonstrates that `pidgy` may \n",
       "export `python` code. \n",
       "As a result the could be run as main scripts using the `runpy` modules.\n",
       "        \n",
       "        import pidgy, importnb, runpy\n",
       "        with pidgy.reuse.pidgyLoader(), importnb.Notebook():\n",
       "            for file in files: runpy.run_path(file)\n",
       "            for module in modules: runpy.run_module(module)\n",
       "\n",
       "\n",
       "\n",
       "    @application.group()\n",
       "    def kernel():\n",
       "`pidgy` is mainly designed to improve the interactive experience\n",
       "of creating literature in computational notebooks. \n",
       "\n",
       "    @kernel.command()\n",
       "    def install(user=False, replace=None, prefix=None):\n",
       "        with pidgy.reuse.pidgyLoader():\n",
       "            from .kernel import shell\n",
       "        dest =shell.install(user=user, replace=replace, prefix=prefix)\n",
       "        click.echo(F\"The pidgy kernel was install in {dest}\")\n",
       "        \n",
       "    @kernel.command()\n",
       "    def uninstall(user=True, replace=None, prefix=None):\n",
       "        with pidgy.reuse.pidgyLoader():\n",
       "            from .kernel import shell\n",
       "        shell.uninstall()\n",
       "        click.echo(F\"The pidgy kernel was removed.\")\n",
       "        \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:26.914676",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:26.804114"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.cli, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"255pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 255.36 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 251.3635,-94 251.3635,4 -4,4\"/>\n",
       "<!-- notebook -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>notebook</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"43.0194\" cy=\"-18\" rx=\"43.0387\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.0194\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">notebook</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;notebook -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;notebook</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M19.3328,-33.1666C12.1551,-43.6641 20.0506,-54 43.0194,-54 58.4515,-54 67.0793,-49.3342 68.9028,-43.0884\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"72.2851,-42.1734 66.7059,-33.1666 65.4506,-43.6868 72.2851,-42.1734\"/>\n",
       "</g>\n",
       "<!-- documentation -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>documentation</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"184.7011\" cy=\"-72\" rx=\"62.8252\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.7011\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">documentation</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;documentation -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;documentation</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M75.1692,-30.2534C93.565,-37.2648 116.9822,-46.1899 137.4385,-53.9865\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"136.3123,-57.3028 146.9032,-57.5938 138.8054,-50.7618 136.3123,-57.3028\"/>\n",
       "</g>\n",
       "<!-- python -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>python</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"184.7011\" cy=\"-18\" rx=\"34.8458\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"184.7011\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">python</text>\n",
       "</g>\n",
       "<!-- notebook&#45;&gt;python -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>notebook&#45;&gt;python</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M83.6197,-11.8294C101.7498,-11.0912 123.1332,-11.0584 141.5523,-11.731\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"141.5748,-15.2355 151.7233,-12.1927 141.8923,-8.2427 141.5748,-15.2355\"/>\n",
       "</g>\n",
       "<!-- python&#45;&gt;notebook -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>python&#45;&gt;notebook</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151.7233,-23.8073C134.5021,-24.7576 113.0534,-24.9895 93.7699,-24.5027\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.7288,-20.9996 83.6197,-24.1706 93.4999,-27.9958 93.7288,-20.9996\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1167d7908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    üï∏(\n",
    "digraph {rankdir=LR notebook->{documentation python->notebook}}\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Reusable computable literature\n",
       "\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "        \"\"\"\n",
       "A primary requirement is that `pidgy` documents can be included\n",
       "in other `pidgy` documents, and, consequently, other `python` tools.\n",
       "To acheive this, `pidgy` modifies\n",
       "how `python` finds `__import__`s, this is acheived with an\n",
       "existing tool called `importnb` that includes\n",
       "`notebook` documents in `sys.path_hooks` used to discover modules.      \n",
       "        \n",
       "        \"\"\"\n",
       "        pidgyLoader(position=-1).__enter__()\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyLoader(importnb.Notebook): \n",
       "        \"\"\"\n",
       "To identify `pidgy` `notebook`s against other notebooks we \n",
       "introduce the hybrid extension `\".md.ipynb\"`.\n",
       "\n",
       "        \"\"\"\n",
       "        extensions = \".md.ipynb\".split()\n",
       "        \n",
       "        def code(self, str): \n",
       "            \"\"\"\n",
       "The `\"code\"` method of the `__import__` loader\n",
       "performs string transforms to code cells.\n",
       "`pidgy` uses the same method \n",
       "that the `shell.input_transformer_manager`.\n",
       "\n",
       "\n",
       "            \"\"\"\n",
       "            with importnb.Notebook(lazy=True):\n",
       "                try: from . import translate\n",
       "                except: import translate\n",
       "            return ''.join(translate.pidgy.transform_cell(str))\n",
       "        \n",
       "        def visit(self, node):\n",
       "            \"\"\"\n",
       "The `\"visit\"` method provides modifications to the\n",
       "abstract syntax tree.\n",
       "            \n",
       "            \"\"\"\n",
       "            with importnb.Notebook():\n",
       "                try: from . import translate\n",
       "                except: import translate\n",
       "            return translate.ReturnYield().visit(node)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:27.481751",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:27.389561"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.reuse, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Deriving files from pidgin documents.\n",
       "\n",
       "We can combine many syntaxes through markdown.\n",
       "\n",
       "\n",
       "\n",
       "There are numerous tools that use the `notebook` format as an intermediate formats\n",
       "for different documents.\n",
       "\n",
       "The original literate programming used latex as the sole export format\n",
       "where as the notebook recognizes quite a few formats:\n",
       "    \n",
       "<details><summary><code>nbconvert</code> can generate <b>12</b> different formats from the files that abide the <code>nbformat</code>\n",
       "schema.</summary>\n",
       "<ul><li>slides</li>\n",
       "<li>markdown</li>\n",
       "<li>rst</li>\n",
       "<li>custom</li>\n",
       "<li>python</li>\n",
       "<li>script</li>\n",
       "<li>notebook</li>\n",
       "<li>asciidoc</li>\n",
       "<li>html</li>\n",
       "<li>pdf</li>\n",
       "<li>selectLanguage</li>\n",
       "<li>latex</li>\n",
       "</ul>\n",
       "</details>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyTranslate(nbconvert.preprocessors.Preprocessor):\n",
       "Translate pidgy cells to pure python cells.\n",
       "        \n",
       "        def preprocess_cell(self, cell, resources, index, ):\n",
       "            import pidgy\n",
       "            tokenizer = pidgy.translate.Tokenizer()\n",
       "            if cell['cell_type'] == 'code':\n",
       "                cell['source'] = pidgy.imports.pidgy.transform_cell(''.join(cell['source']))\n",
       "            return cell, resources\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyNormalize(nbconvert.preprocessors.Preprocessor):\n",
       "Untangle a pidgy notebook into a normalized notebook that explicitly sepearting code and markdown cells.\n",
       "A normalized notebook can be imported by importnb.\n",
       "        \n",
       "        def preprocess(self, nb, resources):\n",
       "            new, tokens = nbformat.v4.new_notebook(), []\n",
       "            for cell in nb.cells:\n",
       "                for token in tokenizer.parse(''.join(cell.source)) if cell.cell_type == 'code' else [{'type': 'paragraph', 'text': ''.join(cell.source)}]:\n",
       "                    new.cells.append((\n",
       "                        nbformat.v4.new_code_cell if token['type'] == 'code' else nbformat.v4.new_markdown_cell\n",
       "                    )(token['text'].splitlines(True)))\n",
       "            return nb, resources\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:27.956704",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:27.861895"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.conversion, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Literature as the test\n",
       "\n",
       "\n",
       "\n",
       "Intertextuallity emerges when \n",
       "the primary target of a program is literature.\n",
       "Some of the literary content may include `\"code\"` `object`s\n",
       "that can be tested to qualify the veracity of these\n",
       "dual signifiers.\n",
       "\n",
       "`pidgy` documents are designed to be tested under\n",
       "multiple formal testing conditions.\n",
       "This is motivated by the `python`ic concept of documentation testing,\n",
       "or `doctest`ing, which in itself is a literate programming style.\n",
       "A `pidgy` document includes `doctest`, it verifies `notebook` `input`/`\"output\"`,\n",
       "and any formally defined tests are collected.\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyModule(importnb.utils.pytest_importnb.NotebookModule):\n",
       "`pidgy` provides a `pytest` plugin that works only on `\".md.ipynb\"` files.\n",
       "The `pidgy.kernel` works directly with `nbval`, install the python packkage and use the --nbval flag.\n",
       "`pidgy` uses features from `importnb` to support standard tests discovery, \n",
       "and `doctest` discovery across all strings.\n",
       "Still working on coverage.\n",
       "The `pidgyModule` permits standard test discovery in notebooks.\n",
       "Functions beginning with `\"test_\"` indicate test functions.\n",
       "\n",
       "        loader = pidgy.reuse.pidgyLoader\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyTests(importnb.utils.pytest_importnb.NotebookTests):\n",
       "if `pidgy` is install then importnb is.\n",
       "        \n",
       "        modules = pidgyModule,\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:28.486628",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:28.396093"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.tests.readme, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### The `pidgy` shell-kernel model\n",
       "\n",
       "\n",
       "The shell is the application either jupyterlab or jupyter notebook, the kernel determines the programming language.  Below we design a just jupyter kernel that can be installed using \n",
       "\n",
       "    !pidgy kernel install\n",
       "\n",
       "\n",
       "    def install(kernel_name='pidgy',\n",
       "        user=True,\n",
       "        replace=None,\n",
       "        prefix=None\n",
       "    ):\n",
       "        return ipykernel.kernelspec.KernelSpecManager().install_kernel_spec(\n",
       "            str(pathlib.Path(globals().get('__file__', pathlib.Path('spec'))).parent/'spec'), kernel_name=kernel_name,\n",
       "            user=user, replace=replace, prefix=prefix)\n",
       "\n",
       "\n",
       "\n",
       "    def uninstall(kernel_name='pidgy',):\n",
       "        ipykernel.kernelspec.KernelSpecManager().remove_kernel_spec(kernel_name)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:28.742581",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:28.649318"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.kernel.shell, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Building the `pidgy` extension\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "The `pidgy` implementation uses the `IPython` configuration\n",
       "and extension system to modify the interactive computing expierence\n",
       "in `jupyter` notebooks.\n",
       "        \n",
       "        translate.load_ipython_extension(shell)\n",
       "1. The primary function of `pidgy` is that it imports `markdown` as formal language for \n",
       "programming multiobjective literate programs.  imports focuses on the indentification of\n",
       "`\"code\" and not\"code\"` that become python code.\n",
       "\n",
       "        testing.load_ipython_extension(shell) \n",
       "2. The `pidgy` specification promotes strong intertextuality between `\"code\" and not\"code\"` \n",
       "objects in a program.  `testing` reinforces that efficacy of the `\"code\"` using\n",
       "documentation tests of `doctest and \"inline\"+\"code\"`.  `pidgy` uses the narrative a formal \n",
       "test for the program.  These tests are executed interactively to ensure the veracity of \n",
       "`\"code\"` signs in the narrative.\n",
       "\n",
       "        reuse.load_ipython_extension(shell)\n",
       "        #debugging.load_ipython_extension(shell)\n",
       "        outputs.load_ipython_extension(shell)\n",
       "3. Literate computing in `pidgy` allows incremental development of `\"code\"` and the co-development of the documentation.\n",
       "`pidgy` interprets the `input` `\"code\"` as a `display`.  `pidgy` uses a `template` language to transclude\n",
       "`object`s from code \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:29.198089",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:29.114973"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.extension, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"461pt\" height=\"170pt\"\n",
       " viewBox=\"0.00 0.00 461.00 170.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 166)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-166 457,-166 457,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_pidgy</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"8,-8 8,-154 262,-154 262,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">new school</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_web</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"270,-8 270,-154 445,-154 445,-8 270,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"357.5\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">old school</text>\n",
       "</g>\n",
       "<!-- pidgy -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>pidgy</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"126\" cy=\"-106\" rx=\"30.0035\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-101.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pidgy</text>\n",
       "</g>\n",
       "<!-- PYTHON -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>PYTHON</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"62\" cy=\"-34\" rx=\"45.9459\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PYTHON</text>\n",
       "</g>\n",
       "<!-- pidgy&#45;&gt;PYTHON -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>pidgy&#45;&gt;PYTHON</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M111.7963,-90.0209C103.6382,-80.843 93.2174,-69.1196 84.0192,-58.7716\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"86.5409,-56.3403 77.2813,-51.1915 81.309,-60.9909 86.5409,-56.3403\"/>\n",
       "</g>\n",
       "<!-- MARKDOWN -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>MARKDOWN</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"190\" cy=\"-34\" rx=\"64.296\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MARKDOWN</text>\n",
       "</g>\n",
       "<!-- pidgy&#45;&gt;MARKDOWN -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>pidgy&#45;&gt;MARKDOWN</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.2037,-90.0209C148.2444,-80.975 158.4832,-69.4564 167.583,-59.2191\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.2367,-61.5019 174.2644,-51.7025 165.0048,-56.8513 170.2367,-61.5019\"/>\n",
       "</g>\n",
       "<!-- WEB -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>WEB</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"364\" cy=\"-106\" rx=\"29.5104\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-101.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">WEB</text>\n",
       "</g>\n",
       "<!-- PASCAL -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>PASCAL</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"321\" cy=\"-34\" rx=\"43.4111\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"321\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PASCAL</text>\n",
       "</g>\n",
       "<!-- WEB&#45;&gt;PASCAL -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>WEB&#45;&gt;PASCAL</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M353.8096,-88.937C348.7281,-80.4284 342.4682,-69.9468 336.7833,-60.4279\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.6987,-58.4833 331.5663,-51.6924 333.6889,-62.0725 339.6987,-58.4833\"/>\n",
       "</g>\n",
       "<!-- TEX -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>TEX</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"410\" cy=\"-34\" rx=\"27.0958\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"410\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">TEX</text>\n",
       "</g>\n",
       "<!-- WEB&#45;&gt;TEX -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>WEB&#45;&gt;TEX</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374.9014,-88.937C380.5155,-80.1496 387.4741,-69.2579 393.7112,-59.4956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"396.7424,-61.2519 399.1769,-50.9405 390.8435,-57.4831 396.7424,-61.2519\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1168715c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "## programming in `markdown and python` \n",
       "[üìì](translate.ipynb)\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "        \"\"\"\n",
       "The `pidgy` `load_ipython_extension`'s primary function transforms the `jupyter`\n",
       "`notebook`s into a literate computing interfaces.\n",
       "`markdown` becomes the primary plain-text format for submitting code,\n",
       "and the `markdown` is translated to `python` source code\n",
       "before compilation.\n",
       "The implementation configures the appropriate\n",
       "features of the `IPython.InteractiveShell` to accomodate\n",
       "the interactive literate programming experience.\n",
       "\n",
       "In this section, we'll implement a `shell.input_transformer_manager`\n",
       "that handles the logical translation of `markdown` to `python`.\n",
       "The translation maintains the source line numbers and \n",
       "normalizes the narrative relative to the source code.  Consequently,\n",
       "introduces new syntaxes at the interfaces between `markdown and python`.\n",
       "\n",
       "        \"\"\"\n",
       "        pidgy_transformer = pidgyTransformer()        \n",
       "        shell.input_transformer_manager = pidgy_transformer\n",
       "        \n",
       "        \"\"\"\n",
       "`IPython` provides configurable interactive `shell` properties.  Some of the configurable properties\n",
       "control how `input` code is translated into valid source code. \n",
       "The `pidgy` translation is managed by a custom `IPython.core.inputtransformer2.TransformerManager`.\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "        >>> shell.input_transformer_manager\n",
       "        <...pidgyTransformer object...>\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "\n",
       "The `shell.input_transformer_manager` applies string transformations to clean up the `input`\n",
       "to be valid `python`.  There are three stages of line of transforms.\n",
       "\n",
       "1. Cleanup transforms that operate on the entire cell `input`.\n",
       "\n",
       "        \"\"\"\"\"\"\n",
       "        >>> shell.input_transformers_cleanup\n",
       "        [<...leading_empty_lines...>, <...leading_indent...>, <...PromptStripper...>, ...]\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "        \n",
       "2. Line transforms that are applied the cell `input` with split lines. \n",
       "This is where `IPython` introduces their bespoke cell magic syntaxes.\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "        >>> shell.input_transformer_manager.line_transforms\n",
       "        [...<...cell_magic...>...]\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "        \n",
       "3. Token transformers that look for specific tokens at the like level.  `IPython`'s default\n",
       "behavior introduces new symbols into the programming language.\n",
       "\n",
       "        \"\"\"\"\"\"\n",
       "        >>> shell.input_transformer_manager.token_transformers\n",
       "        [<...MagicAssign...SystemAssign...EscapedCommand...HelpEnd...>]\n",
       "        \n",
       "        \"\"\"\"\"\"\n",
       "\n",
       "After all of the `input` transformations are complete, the `input` should be valid source that `ast.parse, compile or shell.compile` \n",
       "may accept.\n",
       "\n",
       "        \"\"\"\"\"\"\n",
       "        >>> shell.ast_transformers\n",
       "        [...]\n",
       "        \n",
       "        \"\"\"\n",
       "\n",
       "        if not any(x for x in shell.ast_transformers if isinstance(x, ReturnYield)):\n",
       "            shell.ast_transformers.append(ReturnYield())\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "newline hrule block_code fences heading nptable lheading block_quote list_block block_html def_links def_footnotes table paragraph text\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "    ' '.join(markdown.BlockLexer.default_rules)\n",
       "\n",
       "\n",
       "\n",
       "    class pidgyTransformer(IPython.core.inputtransformer2.TransformerManager):\n",
       "        def pidgy_transform(self, cell: str) -> str: \n",
       "            return self.tokenizer.untokenize(self.tokenizer.parse(''.join(cell)))\n",
       "        \n",
       "        def transform_cell(self, cell):\n",
       "            return super().transform_cell(self.pidgy_transform(cell))\n",
       "        \n",
       "        def _rstrip_lines(self, lines):\n",
       "            return '\\n'.join(map(str.rstrip, ''.join(lines + ['']).splitlines())).splitlines(True)\n",
       "        \n",
       "        def __init__(self, *args, **kwargs):\n",
       "            super().__init__(*args, **kwargs)\n",
       "            self.tokenizer = Tokenizer()\n",
       "            self.line_transforms.append(demojize)\n",
       "            self.line_transforms.append(self._rstrip_lines)\n",
       "\n",
       "        def pidgy_magic(self, *text): \n",
       "            \"\"\"Expand the text to tokens to tokens and \n",
       "            compact as a formatted `\"python\"` code.\"\"\"\n",
       "            return IPython.display.Code(self.pidgy_transform(''.join(text)), language='python')\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    import ast\n",
       "    class ReturnYield(ast.NodeTransformer):\n",
       "        def visit_FunctionDef(self, node): return node\n",
       "        visit_AsyncFunctionDef = visit_FunctionDef\n",
       "        def visit_Return(self, node):\n",
       "            replace = ast.parse('''__import__('IPython').display.display()''').body[0]\n",
       "            replace.value.args = node.value.elts if isinstance(node.value, ast.Tuple) else [node.value]\n",
       "            return ast.copy_location(replace, node)\n",
       "\n",
       "        def visit_Expr(self, node):\n",
       "            if isinstance(node.value, (ast.Yield, ast.YieldFrom)):  return ast.copy_location(self.visit_Return(node.value), node)\n",
       "            return node\n",
       "        \n",
       "        visit_Expression = visit_Expr\n",
       "\n",
       "\n",
       "\n",
       "    def demojize(lines, delimiters=('_', '_')):\n",
       "        str = ''.join(lines)\n",
       "        import tokenize, emoji, stringcase; tokens = []\n",
       "        try:\n",
       "            for token in list(tokenize.tokenize(\n",
       "                __import__('io').BytesIO(str.encode()).readline)):\n",
       "                if token.type == tokenize.ERRORTOKEN:\n",
       "                    string = emoji.demojize(token.string, delimiters=delimiters\n",
       "                                           ).replace('-', '_').replace(\"‚Äô\", \"_\")\n",
       "                    if tokens and tokens[-1].type == tokenize.NAME: tokens[-1] = tokenize.TokenInfo(tokens[-1].type, tokens[-1].string + string, tokens[-1].start, tokens[-1].end, tokens[-1].line)\n",
       "                    else: tokens.append(\n",
       "                        tokenize.TokenInfo(\n",
       "                            tokenize.NAME, string, token.start, token.end, token.line))\n",
       "                else: tokens.append(token)\n",
       "            return tokenize.untokenize(tokens).decode().splitlines(True)\n",
       "        except BaseException: raise SyntaxError(str)\n",
       "\n",
       "\n",
       "\n",
       "    import mistune as markdown, textwrap, __main__, IPython, typing, re, IPython, nbconvert, ipykernel, doctest, ast\n",
       "    __all__ = 'pidgy',\n",
       "\n",
       "\n",
       "\n",
       "    class Tokenizer(markdown.BlockLexer):\n",
       "            \"\"\"\n",
       "##### Tokenizer\n",
       "\n",
       "<details>\n",
       "<summary>Tokenize `input` text into `\"code\" and not \"code\"` tokens that will be translated into valid `python` source.</summary>\n",
       "        \n",
       "            \"\"\"\n",
       "            class grammar_class(markdown.BlockGrammar):\n",
       "                doctest = doctest.DocTestParser._EXAMPLE_RE\n",
       "                default_rules = \"newline hrule block_code fences heading nptable lheading block_quote list_block def_links def_footnotes table paragraph text\".split()\n",
       "\n",
       "            def parse(self, text: str, default_rules=None) -> typing.List[dict]:\n",
       "                if not self.depth: self.tokens = []\n",
       "                with self: tokens = super().parse(whiten(text), default_rules)\n",
       "                if not self.depth: tokens = self.normalize(text, tokens)\n",
       "                return tokens\n",
       "\n",
       "            def parse_doctest(self, m): self.tokens.append({'type': 'paragraph', 'text': m.group(0)})\n",
       "\n",
       "            def parse_fences(self, m):\n",
       "                if m.group(2): self.tokens.append({'type': 'paragraph', 'text': m.group(0)})\n",
       "                else: super().parse_fences(m)\n",
       "\n",
       "            def parse_hrule(self, m):\n",
       "                self.tokens.append({'type': 'hrule', 'text': m.group(0)})\n",
       "\n",
       "            def normalize(self, text, tokens):\n",
       "                \"\"\"Combine non-code tokens into contiguous blocks.\"\"\"\n",
       "                compacted = []\n",
       "                while tokens:\n",
       "                    token = tokens.pop(0)\n",
       "                    if 'text' not in token: continue\n",
       "                    else: \n",
       "                        if not token['text'].strip(): continue\n",
       "                        block, body = token['text'].splitlines(), \"\"\n",
       "                    while block:\n",
       "                        line = block.pop(0)\n",
       "                        if line:\n",
       "                            before, line, text = text.partition(line)\n",
       "                            body += before + line\n",
       "                    if token['type']=='code':\n",
       "                        compacted.append({'type': 'code', 'lang': None, 'text': body})\n",
       "                    else:\n",
       "                        if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "                            compacted[-1]['text'] += body\n",
       "                        else: compacted.append({'type': 'paragraph', 'text': body})\n",
       "                if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "                    compacted[-1]['text'] += text\n",
       "                elif text.strip():\n",
       "                    compacted.append({'type': 'paragraph', 'text': text})\n",
       "                return compacted\n",
       "\n",
       "            depth = 0\n",
       "            def __enter__(self): self.depth += 1\n",
       "            def __exit__(self, *e): self.depth -= 1\n",
       "\n",
       "            def untokenize(self, tokens: œÑ.List[dict], source: str = \"\"\"\"\"\", last: int =0) -> str:\n",
       "                INDENT = indent = base_indent(tokens) or 4\n",
       "                for i, token in enumerate(tokens):\n",
       "                    object = token['text']\n",
       "                    if token and token['type'] == 'code':\n",
       "                        if object.lstrip().startswith(FENCE):\n",
       "\n",
       "                            object = ''.join(''.join(object.partition(FENCE)[::2]).rpartition(FENCE)[::2])\n",
       "                            indent = INDENT + num_first_indent(object)\n",
       "                            object = textwrap.indent(object, INDENT*SPACE)\n",
       "\n",
       "                        if object.lstrip().startswith(MAGIC):  ...\n",
       "                        else: indent = num_last_indent(object)\n",
       "                    elif not object: ...\n",
       "                    else:\n",
       "                        object = textwrap.indent(object, indent*SPACE)\n",
       "                        for next in tokens[i+1:]:\n",
       "                            if next['type'] == 'code':\n",
       "                                next = num_first_indent(next['text'])\n",
       "                                break\n",
       "                        else: next = indent       \n",
       "                        Œî = max(next-indent, 0)\n",
       "\n",
       "                        if not Œî and source.rstrip().rstrip(CONTINUATION).endswith(COLON): \n",
       "                            Œî += 4\n",
       "\n",
       "                        spaces = num_whitespace(object)\n",
       "                        \"what if the spaces are ling enough\"\n",
       "                        object = object[:spaces] + Œî*SPACE+ object[spaces:]\n",
       "                        if not source.rstrip().rstrip(CONTINUATION).endswith(QUOTES): \n",
       "                            object = quote(object)\n",
       "                    source += object\n",
       "\n",
       "                for token in reversed(tokens):\n",
       "                    if token['text'].strip():\n",
       "                        if token['type'] != 'code': \n",
       "                            source = source.rstrip() + SEMI\n",
       "                        break\n",
       "                        \n",
       "                return source\n",
       "            \n",
       "    for x in \"default_rules footnote_rules list_rules\".split():\n",
       "        setattr(Tokenizer, x, list(getattr(Tokenizer, x)))\n",
       "        getattr(Tokenizer, x).insert(getattr(Tokenizer, x).index('block_code'), 'doctest')\n",
       "        \n",
       "    ...\n",
       "    \"\"\"\n",
       "</details>&nbsp;\n",
       "\n",
       "    \"\"\"\n",
       "    pidgy = pidgyTransformer()\n",
       "\n",
       "\n",
       "A potential outcome of a `pidgy` program is reusable code. \n",
       "\n",
       "Import pidgy notebooks as modules.\n",
       "\n",
       "\n",
       "    graphviz.Source(\n",
       "digraph{rankdir=UD \n",
       "subgraph cluster_pidgy {label=\"new school\" pidgy->{PYTHON MARKDOWN}}\n",
       "subgraph cluster_web {label=\"old school\" WEB->{PASCAL TEX} }}\n",
       "    \n",
       "    )"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:29.745877",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:29.587577"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## programming in `markdown and python` \n",
    "[üìì]({{pathlib.Path(pidgy.translate.__file__).name}})\n",
    "\n",
    "\n",
    "{{appendix.exports(pidgy.translate, change=2)}}\n",
    "\n",
    "    graphviz.Source(\n",
    "digraph{rankdir=UD \n",
    "subgraph cluster_pidgy {label=\"new school\" pidgy->{PYTHON MARKDOWN}}\n",
    "subgraph cluster_web {label=\"old school\" WEB->{PASCAL TEX} }}\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Weaving cells in pidgin programs\n",
       "\n",
       "\n",
       "\n",
       "pidgin programming is an incremental approach to documents.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:30.648545",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:30.554979"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{appendix.exports(pidgy.outputs, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### testing `\"code\"` in the `markdown` narrative.\n",
       "[üìî](interactive.md.ipynb)\n",
       "\n",
       "    import IPython as python, doctest, textwrap\n",
       "    pidgy= None\n",
       "\n",
       "\n",
       "\n",
       "In literate programs, `\"code\"` is deeply entangled with the narrative.\n",
       "`\"code\"` object can signify meaning and can be validated through testing.\n",
       "`python` introduced the `doctest` literate programming convention that indicates some text in a narrative can be tested.\n",
       "`pidgy` extends the `doctest` opinion to the inline markdown code.\n",
       "Each time a `pidgy` cell is executed, the `doctest`s and inline code are executed ensuring that\n",
       "any code in a `pidgy` program is valid.\n",
       "\n",
       "\n",
       "\n",
       "    def post_run_cell(result):\n",
       "        result.runner = test_markdown_string(result.info.raw_cell, IPython.get_ipython(), False, doctest.ELLIPSIS)\n",
       "\n",
       "    def load_ipython_extension(shell): \n",
       "        unload_ipython_extension(shell)\n",
       "        shell.events.register('post_run_cell', post_run_cell)\n",
       "\n",
       "\n",
       "\n",
       "    import doctest, contextlib, mistune as markdown, re, ast, __main__, IPython, operator\n",
       "    shell = IPython.get_ipython()\n",
       "\n",
       "\n",
       "`test_markdown_string` extends the standard python `doctest` tools \n",
       "to inline code objects written in markdown.  \n",
       "This approach compliments are markdown forward programming language to test\n",
       "intertextual references between code and narrative.\n",
       "\n",
       "\n",
       "    INLINE = re.compile(\n",
       "        markdown.InlineGrammar.code\n",
       "        .pattern[1:]\n",
       "        .replace('[\\s\\S]*', '?P<source>[\\s\\S]+')\n",
       "        .replace('+)\\s*', '{1,2})(?P<indent>\\s{0})'), \n",
       "    )\n",
       "\n",
       "\n",
       "    (TICK,), SPACE = '`'.split(), ' '\n",
       "\n",
       "\n",
       "\n",
       "    import doctest\n",
       "\n",
       "\n",
       "\n",
       "    def test_markdown_string(str, shell=shell, verbose=False, compileflags=None):\n",
       "        globs, filename = shell.user_ns, F\"In[{shell.last_execution_result.execution_count}]\"\n",
       "        runner = doctest.DocTestRunner(verbose=verbose, optionflags=compileflags)  \n",
       "        parsers = DocTestParser(runner), InlineDoctestParser(runner)\n",
       "        parsers = {\n",
       "            parser: doctest.DocTestFinder(verbose, parser).find(str, filename) for parser in parsers\n",
       "        }\n",
       "        examples = sum([test.examples for x in parsers.values() for test in x], [])\n",
       "        examples.sort(key=operator.attrgetter('lineno'))\n",
       "        with ipython_compiler(shell):\n",
       "            for example in examples:\n",
       "                for parser, value in parsers.items():\n",
       "                    for value in value:\n",
       "                        if example in value.examples:\n",
       "                            with parser:\n",
       "                                runner.run(doctest.DocTest(\n",
       "                                    [example], globs, value.name, filename, example.lineno, value.docstring\n",
       "                                ), compileflags=compileflags, clear_globs=False)\n",
       "        shell.log.info(F\"In[{shell.last_execution_result.execution_count}]: {runner.summarize()}\")\n",
       "        return runner\n",
       "\n",
       "\n",
       "\n",
       "    @contextlib.contextmanager\n",
       "    def ipython_compiler(shell):\n",
       "        def compiler(input, filename, symbol, *args, **kwargs):\n",
       "            nonlocal shell\n",
       "            return shell.compile(\n",
       "                ast.Interactive(\n",
       "                    body=shell.transform_ast(\n",
       "                        shell.compile.ast_parse(shell.transform_cell(textwrap.indent(input, ' '*4)))\n",
       "                    ).body\n",
       "                ),\n",
       "                F\"In[{shell.last_execution_result.execution_count}]\",\n",
       "                \"single\",\n",
       "            )\n",
       "\n",
       "        yield setattr(doctest, \"compile\", compiler)\n",
       "        doctest.compile = compile\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:31.312104",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:31.195680"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### testing `\"code\"` in the `markdown` narrative.\n",
    "[üìî]({{pathlib.Path(pidgy.tests.interactive.__file__).name}})\n",
    "\n",
    "{{appendix.exports(pidgy.tests.interactive, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## `pidgy` metasyntax at language interfaces.\n",
       "[üìó](test_pidgin_syntax.md.ipynb)\n",
       "\n",
       "The combinations of document, programming, and templating languages\n",
       "provides unique syntaxes as the interfaces.\n",
       "\n",
       "This is a code string\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "`pidgy` programming is a `markdown`-forward approach to programming,\n",
       "it extends computational to interactive literate programming environment.\n",
       "One feature `markdown` uses to identify `markdown.BlockGrammar.block_code`\n",
       "is indented code.\n",
       "`pidgy` starts here, all cells are `markdown` forward, and code is identified as indented code.\n",
       "\n",
       "            \"This is a code string\"\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "##### Code fences\n",
       "\n",
       "Some folks may prefer code fences and they may be used without a language specified.\n",
       "\n",
       "\n",
       "```\n",
       "\"This is code\"\n",
       "```\n",
       "\n",
       "```python\n",
       "\"This is not code.\"\n",
       "```\n",
       "\n",
       "\n",
       "\n",
       "    class DocStrings:\n",
       "##### Docstrings\n",
       "\n",
       "\n",
       "    >>> assert DocStrings.__doc__.startswith('### Docstrings')\n",
       "    >>> DocStrings.function_docstring.__doc__\n",
       "    '`DocStrings.function_docstring`s appear as native docstrings, ...'\n",
       "\n",
       "\n",
       "        def function_docstring():\n",
       "`DocStrings.function_docstring`s appear as native docstrings, but render as `markdown`.\n",
       "            \n",
       "            ...\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "    import doctest\n",
       "##### `doctest`\n",
       "\n",
       "    >>> assert True\n",
       "    >>> print\n",
       "    <built-in function print>\n",
       "    >>> pidgy\n",
       "    <module...__init__.py'>\n",
       "\n",
       "\n",
       "\n",
       "##### templating\n",
       "\n",
       "filters\n",
       "jinja docs\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "text/markdown": {
       "end_time": "2020-02-11T18:58:31.548478",
       "modules": [],
       "names": [],
       "start_time": "2020-02-11T18:58:31.450370"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## `pidgy` metasyntax at language interfaces.\n",
    "[üìó]({{pathlib.Path(test_pidgin_syntax.__file__).name}})\n",
    "\n",
    "The combinations of document, programming, and templating languages\n",
    "provides unique syntaxes as the interfaces.\n",
    "\n",
    "{{appendix.exports(test_pidgin_syntax, change=2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"461pt\" height=\"170pt\"\n",
       " viewBox=\"0.00 0.00 461.00 170.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 166)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-166 457,-166 457,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_pidgy</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"8,-8 8,-154 262,-154 262,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">new school</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_web</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"270,-8 270,-154 445,-154 445,-8 270,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"357.5\" y=\"-138.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">old school</text>\n",
       "</g>\n",
       "<!-- pidgy -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>pidgy</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"126\" cy=\"-106\" rx=\"30.0035\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-101.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pidgy</text>\n",
       "</g>\n",
       "<!-- PYTHON -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>PYTHON</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"62\" cy=\"-34\" rx=\"45.9459\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PYTHON</text>\n",
       "</g>\n",
       "<!-- pidgy&#45;&gt;PYTHON -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>pidgy&#45;&gt;PYTHON</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M111.7963,-90.0209C103.6382,-80.843 93.2174,-69.1196 84.0192,-58.7716\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"86.5409,-56.3403 77.2813,-51.1915 81.309,-60.9909 86.5409,-56.3403\"/>\n",
       "</g>\n",
       "<!-- MARKDOWN -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>MARKDOWN</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"190\" cy=\"-34\" rx=\"64.296\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">MARKDOWN</text>\n",
       "</g>\n",
       "<!-- pidgy&#45;&gt;MARKDOWN -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>pidgy&#45;&gt;MARKDOWN</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.2037,-90.0209C148.2444,-80.975 158.4832,-69.4564 167.583,-59.2191\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.2367,-61.5019 174.2644,-51.7025 165.0048,-56.8513 170.2367,-61.5019\"/>\n",
       "</g>\n",
       "<!-- WEB -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>WEB</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"364\" cy=\"-106\" rx=\"29.5104\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-101.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">WEB</text>\n",
       "</g>\n",
       "<!-- PASCAL -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>PASCAL</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"321\" cy=\"-34\" rx=\"43.4111\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"321\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">PASCAL</text>\n",
       "</g>\n",
       "<!-- WEB&#45;&gt;PASCAL -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>WEB&#45;&gt;PASCAL</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M353.8096,-88.937C348.7281,-80.4284 342.4682,-69.9468 336.7833,-60.4279\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.6987,-58.4833 331.5663,-51.6924 333.6889,-62.0725 339.6987,-58.4833\"/>\n",
       "</g>\n",
       "<!-- TEX -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>TEX</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"410\" cy=\"-34\" rx=\"27.0958\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"410\" y=\"-29.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">TEX</text>\n",
       "</g>\n",
       "<!-- WEB&#45;&gt;TEX -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>WEB&#45;&gt;TEX</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374.9014,-88.937C380.5155,-80.1496 387.4741,-69.2579 393.7112,-59.4956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"396.7424,-61.2519 399.1769,-50.9405 390.8435,-57.4831 396.7424,-61.2519\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1168e57b8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    √ò and üï∏(\n",
    "digraph{rankdir=UD \n",
    "subgraph cluster_pidgy {label=\"new school\" pidgy->{PYTHON MARKDOWN}}\n",
    "subgraph cluster_web {label=\"old school\" WEB->{PASCAL TEX} }}\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook paper.md.ipynb to markdown\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    if __name__ == '__main__':\n",
    "        !jupyter nbconvert --to markdown --TemplateExporter.exclude_input=True --stdout paper.md.ipynb > readme.md\n",
    "    ...;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pidgy 3",
   "language": "python",
   "name": "pidgy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
