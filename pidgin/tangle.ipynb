{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, mistletoe, textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote(str, punc=''):\n",
    "    str, leading_ws = ''.join(str), []\n",
    "    lines = str.splitlines(True)\n",
    "    _ = '\"\"\"'\n",
    "    if _ in str: _ = \"'''\"\n",
    "    if not str.strip(): _ = punc = ''\n",
    "    while lines and not lines[0]: leading_ws.append(lines.pop())\n",
    "    str = ''.join(lines)\n",
    "    end = len(str.rstrip())\n",
    "    str, ending_ws = str[:end], str[end:]\n",
    "    if str and str.endswith(_[0]): str += ' '                    \n",
    "    return F\"{''.join(leading_ws)}{_}{str}{_}{punc}{ending_ws}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_line(lines, line=''):\n",
    "    for line in lines or ['']: \n",
    "        if line.strip(): break\n",
    "    return line\n",
    "\n",
    "def get_line_indent(line):  return len(line) - len(line.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmptyCodeBlock = mistletoe.block_token.BlockCode('')\n",
    "EmptyCodeBlock.children = [mistletoe.span_token.RawText('')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_string_as_document(callable):\n",
    "    @functools.wraps(callable)\n",
    "    def caller(self, token):\n",
    "        if isinstance(token, str):\n",
    "            self.original = list(map(str.rstrip, ''.join(token).splitlines()))\n",
    "            self.final, self.buffer, self.min_indent = [], mistletoe.span_token.RawText(''), 0\n",
    "            token = mistletoe.Document(token)\n",
    "            isinstance(token.children[-1], mistletoe.block_token.BlockCode) or token.children.append(EmptyCodeBlock)        \n",
    "        return callable(self, token)\n",
    "    return caller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownPythonRendererContext(mistletoe.base_renderer.BaseRenderer):\n",
    "    _original_block_tokens = None\n",
    "    _original_span_tokens = None\n",
    "    _active_block_tokens = None\n",
    "    _active_span_tokens = None\n",
    "    def __enter__(self):\n",
    "        self._original_block_tokens = mistletoe.block_token._token_types\n",
    "        self._original_span_tokens = mistletoe.span_token._token_types\n",
    "        mistletoe.block_token._token_types = self._active_block_tokens or self._original_block_tokens\n",
    "        mistletoe.span_token._token_types = self._active_span_tokens or self._original_span_tokens\n",
    "        return super().__enter__()\n",
    "    \n",
    "    def __exit__(self, *exc):\n",
    "        mistletoe.block_token._token_types = self._original_block_tokens\n",
    "        mistletoe.span_token._token_types = self._original_span_tokens\n",
    "        return super().__exit__(*exc)\n",
    "    \n",
    "    render = render_string_as_document(mistletoe.base_renderer.BaseRenderer.render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownPython(MarkdownPythonRendererContext):\n",
    "    _active_block_tokens = [mistletoe.block_token.List, mistletoe.block_token.BlockCode, mistletoe.block_token.Paragraph]\n",
    "    def render_document(self, token, punctation = ''): \n",
    "        [self.render(child) for child in token.children if hasattr(child, 'children')]\n",
    "        source = '\\n'.join(self.final)\n",
    "        if token.children[-1] == EmptyCodeBlock:\n",
    "            # IPython use the magic function if the string is not stripped\n",
    "            source = source.rstrip() +';'\n",
    "        return source\n",
    "    def render_paragraph(self, token): \n",
    "        \"\"\"Paragraphs are staged in the buffer so they can be indented.\"\"\"\n",
    "        for child in token.children:  \n",
    "            self.buffer.content += child.content + '\\n'\n",
    "        return ''\n",
    "        \n",
    "    def render_block_code(self, token):\n",
    "        \n",
    "        buffer = self.buffer.content.splitlines()\n",
    "        while buffer and not buffer[0]:   \n",
    "            self.final.append(buffer.pop(0))\n",
    "        body = '\\n'.join(buffer)\n",
    "\n",
    "        block = token.children[0].content.splitlines()\n",
    "        last_line = get_first_line(reversed(self.final))\n",
    "        prior_indent = get_line_indent(last_line)\n",
    "        \n",
    "        definition, returns = last_line.rstrip().endswith(':'), last_line.lstrip().startswith('return')\n",
    "\n",
    "        this_indent = get_line_indent(get_first_line(block))\n",
    "            \n",
    "        if body.strip() and not self.min_indent: self.min_indent = this_indent\n",
    "\n",
    "        indent = max(self.min_indent, (returns and min or max)(prior_indent, this_indent))\n",
    "        indent += 4 * (definition and prior_indent == indent)\n",
    "            \n",
    "        self.final.extend(textwrap.indent(quote(body), ' '*indent).splitlines() + block) \n",
    "\n",
    "        self.buffer.content = ''\n",
    "        return ''\n",
    "        \n",
    "    \n",
    "    def render(self, token: [str, 'Token']):\n",
    "        if isinstance(token, mistletoe.block_token.Document): ...\n",
    "        elif isinstance(token, (mistletoe.block_token.Paragraph, mistletoe.block_token.BlockCode)):    \n",
    "            lines = []\n",
    "            for child in token.children:\n",
    "                for line in map(str.strip, getattr(child, 'content', '').splitlines()):\n",
    "                    if line:\n",
    "                        while self.original and (not lines or (line not in lines[-1])):  \n",
    "                            lines.append(self.original.pop(0).rstrip())\n",
    "            token = type(token)([])\n",
    "            token.children = mistletoe.span_token.RawText('\\n'.join(lines)),\n",
    "\n",
    "        return super().render(token)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_python(str): \n",
    "    with MarkdownPython() as object: return object.render(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(markdown_to_python(\"\"\"asdfadf\n",
    "        \n",
    "        PRINT\n",
    "        range\n",
    "\n",
    "\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarkdownPythonRendererContext._original_span_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownUserExpressions(MarkdownPythonRendererContext):\n",
    "    _active_block_tokens = [mistletoe.block_token.List, mistletoe.block_token.Paragraph]\n",
    "    def render_inline_code(self, token):\n",
    "        return self.expressions.append(token.children[0].content) or ''\n",
    "    def render_line_break(self, token):  return  ''\n",
    "    \n",
    "    def render_document(self, token):\n",
    "        self.expressions = []\n",
    "        if hasattr(token, 'children'): super().render_inner(token)\n",
    "        return self.expressions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownPythonUserExpressions(MarkdownPython):\n",
    "    user_expressions = None\n",
    "    _active_span_tokens = [\n",
    "        mistletoe.span_token.InlineCode, mistletoe.span_token.RawText\n",
    "    ]\n",
    "    def render_paragraph(self, token): \n",
    "        \"\"\"Paragraphs are staged in the buffer so they can be indented.\"\"\"\n",
    "        buffer = ''\n",
    "        for child in token.children:  \n",
    "            buffer += child.content + '\\n'\n",
    "        self.buffer.content += buffer\n",
    "        with MarkdownUserExpressions() as user_expressions:\n",
    "            self.user_expressions.extend(user_expressions.render(mistletoe.Document(buffer)))\n",
    "        return super().render_paragraph(token)\n",
    "\n",
    "    def render_document(self, token):\n",
    "        return super().render_document(token), self.user_expressions\n",
    "    def render_inner(self, token):\n",
    "        return super().render_inner(token) if hasattr(token, 'children') else ''\n",
    "    \n",
    "    def render(self, token):\n",
    "        self.user_expressions = self.user_expressions or []\n",
    "        return super().render(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_to_python_user_expressions(str): \n",
    "    with MarkdownPythonUserExpressions() as object: \n",
    "        return object.render(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"\"\"Notes from meeting with Siu\\nNotes from meeting with Siu\\n\\nPrevious experience compiling UDFs with numba:\\nTry to create special target for Numba to emit code for cloudera database Impala\\nhttps://github.com/cloudera/impyla/tree/udf\\nNumba generate LLVM ir which cloudera directly consumes\\nInline this directly in database\\nGets tricky as LLVM versions change\\nMore than four years ago\\nApproach involves too much internals\\nLesson learned: try not to go to deep into internals of Numba\\nMain goal to be execute\\nNumba never considers cross compiling\\nWe could get numba to cross compile, but this is not supported yet\\nTwo options: (both would work according to Siu)\\nEmbedding\\nIt doesn’t ever free the function that is loaded\\nBecause numba types are immortal\\nBecause each type is unique\\n\\nPrevious experience compiling UDFs with numba:\\nTry to create special target for Numba to emit code for cloudera database Impala\\nhttps://github.com/cloudera/impyla/tree/udf\\nNumba generate LLVM ir which cloudera directly consumes\\nInline this directly in database\\nGets tricky as LLVM versions change\\nMore than four years ago\\nApproach involves too much internals\\nLesson learned: try not to go to deep into internals of Numba\\nMain goal to be execute\\nNumba never considers cross compiling\\nWe could get numba to cross compile, but this is not supported yet\\nTwo options: (both would work according to Siu)\\nEmbedding\\nIt doesn’t ever free the function that is loaded\\nBecause numba types are immortal\\nBecause each type is unique\\n\\n\\nEmit static shared library\\nHow could we load and unload this?\\nIt is possible to generate regular shared libraries from Numba, that are not python specific\\nSee note below regarding system linker requirement\\nGPU backend\\nFunctions can be unloaded\\nCannot generate shared library for GPU backend\\nRecommended: shared library approach:\\nAOT documentation: http://numba.pydata.org/numba-doc/latest/user/pycc.html?highlight=aot\\nThis might do too much, focuses on user interface\\nWe could also manually generate wrappers like we do for numba-xnd\\nhttps://github.com/Quansight/numba-xnd/blob/9a914ea76442385ada1940bde963a14faad9dee3/numba_xnd/gumath.py#L158-L199\\nNOTE: llvm doesn’t have linker. All it can do is generate `.o` files. We have to use system linker to generate actual shared library\\nIPC approach\\nSend data from mapd to python over IPC and call it\\n\\n\\nEmit static shared library\\nHow could we load and unload this?\\nIt is possible to generate regular shared libraries from Numba, that are not python specific\\nSee note below regarding system linker requirement\\nGPU backend\\nFunctions can be unloaded\\nCannot generate shared library for GPU backend\\nRecommended: shared library approach:\\nAOT documentation: http://numba.pydata.org/numba-doc/latest/user/pycc.html?highlight=aot\\nThis might do too much, focuses on user interface\\nWe could also manually generate wrappers like we do for numba-xnd\\nhttps://github.com/Quansight/numba-xnd/blob/9a914ea76442385ada1940bde963a14faad9dee3/numba_xnd/gumath.py#L158-L199\\nNOTE: llvm doesn’t have linker. All it can do is generate `.o` files. We have to use system linker to generate actual shared library\\nIPC approach\\nSend data from mapd to python over IPC and call it\\n\\nFollow up  notes regarding IPC approach:\\nProvides a quick prototype as communication would be in between two Python processes: one embedded in mapd and other in a thread (Ah I didn\\'t realize we would also embed Python in MapD. Do we need Python in MapD now that we can use IPC to move the data to the python process running Numba?\\nPython in MapD process is not necessary provided that one can use some C++ implementation of IPC. I was just thinking that it would be easier (more flexible) to develop in Python. Getting the UDF sources from client, firing up a Python process, sending the source there, providing the mapd data via IPC (results would be stored in-place to IPC wrapped memory), etc are the tasks for MapD process.\\n)\\nWhen the running Python process dies, the mapd process will not be affected\\nWe could use arrow IPC for data sharing. Might work also when using CUDA.\\nShould we have one Python-numba process for different UDFs or would there be a separate numba process for each UDF?\\n\\nFollow up  notes regarding IPC approach:\\nProvides a quick prototype as communication would be in between two Python processes: one embedded in mapd and other in a thread (Ah I didn\\'t realize we would also embed Python in MapD. Do we need Python in MapD now that we can use IPC to move the data to the python process running Numba?\\nPython in MapD process is not necessary provided that one can use some C++ implementation of IPC. I was just thinking that it would be easier (more flexible) to develop in Python. Getting the UDF sources from client, firing up a Python process, sending the source there, providing the mapd data via IPC (results would be stored in-place to IPC wrapped memory), etc are the tasks for MapD process.\\n)\\nWhen the running Python process dies, the mapd process will not be affected\\nWe could use arrow IPC for data sharing. Might work also when using CUDA.\\nShould we have one Python-numba process for different UDFs or would there be a separate numba process for each UDF?\\n\\n*    Isolated and unloadable execution engine of jit code:\\n    https://github.com/numba/numba/issues/3464\\n    This feature request assumes numba in mapd process.\\n\\n*    Isolated and unloadable execution engine of jit code:\\n    https://github.com/numba/numba/issues/3464\\n    This feature request assumes numba in mapd process.\\n\\n\\n> Internal MVP: allow users to do what they can with extension functions at to be loaded at runtime.\\n\\n\\n> Internal MVP: allow users to do what they can with extension functions at to be loaded at runtime.\\n\\nWith quansight:\\n\\nWith quansight:\\n\\n\\nTODO for next two weeks: create diagram\\n\\n\\nTODO for next two weeks: create diagram\\n\\nThey don’t like IPC process as much\\nDon’t worry too much about unloading first\\nWe want to be able to run them in parallel on multiple threads\\n\\nThey don’t like IPC process as much\\nDon’t worry too much about unloading first\\nWe want to be able to run them in parallel on multiple threads\"\"\";',\n",
       " ['.o'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_to_python_user_expressions(\"\"\"Notes from meeting with Siu\n",
    "\n",
    "Previous experience compiling UDFs with numba:\n",
    "Try to create special target for Numba to emit code for cloudera database Impala\n",
    "https://github.com/cloudera/impyla/tree/udf\n",
    "Numba generate LLVM ir which cloudera directly consumes\n",
    "Inline this directly in database\n",
    "Gets tricky as LLVM versions change\n",
    "More than four years ago\n",
    "Approach involves too much internals\n",
    "Lesson learned: try not to go to deep into internals of Numba\n",
    "Main goal to be execute \n",
    "Numba never considers cross compiling\n",
    "We could get numba to cross compile, but this is not supported yet\n",
    "Two options: (both would work according to Siu)\n",
    "Embedding\n",
    "It doesn’t ever free the function that is loaded\n",
    "Because numba types are immortal\n",
    "Because each type is unique\n",
    "\n",
    "\n",
    "Emit static shared library\n",
    "How could we load and unload this?\n",
    "It is possible to generate regular shared libraries from Numba, that are not python specific\n",
    "See note below regarding system linker requirement\n",
    "GPU backend\n",
    "Functions can be unloaded\n",
    "Cannot generate shared library for GPU backend\n",
    "Recommended: shared library approach:\n",
    "AOT documentation: http://numba.pydata.org/numba-doc/latest/user/pycc.html?highlight=aot\n",
    "This might do too much, focuses on user interface\n",
    "We could also manually generate wrappers like we do for numba-xnd\n",
    "https://github.com/Quansight/numba-xnd/blob/9a914ea76442385ada1940bde963a14faad9dee3/numba_xnd/gumath.py#L158-L199\n",
    "NOTE: llvm doesn’t have linker. All it can do is generate `.o` files. We have to use system linker to generate actual shared library\n",
    "IPC approach\n",
    "Send data from mapd to python over IPC and call it\n",
    "\n",
    "Follow up  notes regarding IPC approach:\n",
    "Provides a quick prototype as communication would be in between two Python processes: one embedded in mapd and other in a thread (Ah I didn't realize we would also embed Python in MapD. Do we need Python in MapD now that we can use IPC to move the data to the python process running Numba?\n",
    "Python in MapD process is not necessary provided that one can use some C++ implementation of IPC. I was just thinking that it would be easier (more flexible) to develop in Python. Getting the UDF sources from client, firing up a Python process, sending the source there, providing the mapd data via IPC (results would be stored in-place to IPC wrapped memory), etc are the tasks for MapD process.\n",
    ")\n",
    "When the running Python process dies, the mapd process will not be affected\n",
    "We could use arrow IPC for data sharing. Might work also when using CUDA.\n",
    "Should we have one Python-numba process for different UDFs or would there be a separate numba process for each UDF?\n",
    "\n",
    "*    Isolated and unloadable execution engine of jit code:\n",
    "    https://github.com/numba/numba/issues/3464\n",
    "    This feature request assumes numba in mapd process.\n",
    "\n",
    "\n",
    "> Internal MVP: allow users to do what they can with extension functions at to be loaded at runtime.\n",
    "\n",
    "With quansight: \n",
    "\n",
    "\n",
    "TODO for next two weeks: create diagram\n",
    "\n",
    "They don’t like IPC process as much\n",
    "Don’t worry too much about unloading first\n",
    "We want to be able to run them in parallel on multiple threads\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "    source, user_expressions = markdown_to_python_user_expressions('testiong `range` asdfkjadf asdfkjhaskdjfh `print`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'mistletoe.span_token.EscapeSequence'>, <class 'mistletoe.span_token.Strikethrough'>, <class 'mistletoe.span_token.AutoLink'>, <class 'mistletoe.span_token.CoreTokens'>, <class 'mistletoe.span_token.InlineCode'>, <class 'mistletoe.span_token.RawText'>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('    \"\"\"This is all working `print(a)`\\n    This is all working `print(a)`\"\"\"\\n\\n    a = 10\\n\\n    \"\"\"---\\n\\n    ---\"\"\";',\n",
       " ['print(a)'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    markdown_to_python_user_expressions(\"\"\"This is all working `print(a)`\n",
    "\n",
    "        a = 10\n",
    "\n",
    "    ---\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"\"\"# Hmm what the fuck\\n# Hmm what the fuck\"\"\";', [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    markdown_to_python_user_expressions(\"\"\"# Hmm what the fuck\n",
    "\n",
    "    * <https://docs.google.com/document/d/1cejQ1SGD4-dNOzsueUq5Fx_V4gKjEgNTDxr6tC__PVw/edit?usp=sharing>\n",
    "    * <https://docs.google.com/document/d/1cejQ1SGD4-dNOzsueUq5Fx_V4gKjEgNTDxr6tC__PVw/edit?usp=sharing>\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
